{
  "id": "snapshot_1768320626294_pdh8rioxs",
  "approvalId": "approval_1768320626284_86ddnl0pj",
  "approvalTitle": "CFST XGBoost Pipeline Design Approval",
  "version": 1,
  "timestamp": "2026-01-13T16:10:26.294Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Design Document\n\n## Overview\n\n本项目设计一个基于XGBoost的机器学习管道，用于预测CFST（钢管混凝土）柱的极限承载力。设计遵循模块化原则，将数据加载、预处理、模型训练、评估、预测和可视化功能分离为独立组件，构建一个可扩展、可维护的多截面统一预测系统。\n\n## Steering Document Alignment\n\n### 技术架构原则\n- **模块化设计**: 每个组件有单一职责，通过清晰的接口进行通信\n- **配置驱动**: 使用配置文件管理模型参数、数据路径和训练设置\n- **可重复性**: 确保模型训练过程可复现，支持版本控制\n- **工程化实践**: 遵循ML工程最佳实践，包括数据验证、错误处理和日志记录\n\n### 项目结构规范\n```\ncfst-xgboost-pipeline/\n├── config/                    # 配置文件\n│   └── config.yaml           # 主配置文件\n│\n├── data/                     # 数据目录\n│   ├── raw/                  # 原始数据\n│   ├── processed/            # 处理后数据\n│   └── models/               # 保存的模型\n│\n├── src/                      # 源代码\n│   ├── __init__.py\n│   ├── data_loader.py        # 数据加载器\n│   ├── preprocessor.py       # 数据预处理\n│   ├── model_trainer.py      # 模型训练器\n│   ├── evaluator.py          # 模型评估器\n│   ├── predictor.py          # 预测器\n│   ├── visualizer.py         # 可视化器\n│   └── utils/                # 工具函数\n│       ├── __init__.py\n│       ├── logger.py         # 日志配置\n│       └── metrics.py        # 评估指标\n│\n├── notebooks/                # Jupyter notebooks\n│   └── analysis.ipynb        # 分析 notebook\n│\n├── tests/                    # 测试代码\n│   ├── test_data_loader.py\n│   ├── test_preprocessor.py\n│   ├── test_model_trainer.py\n│   └── test_evaluator.py\n│\n├── main.py                   # 主入口\n├── train.py                  # 训练脚本\n├── predict.py                # 预测脚本\n└── requirements.txt          # 依赖包\n```\n\n## Code Reuse Analysis\n\n### 现有组件利用\n本项目为新建项目，无现有代码库可重用。但会利用以下开源库和最佳实践：\n\n- **XGBoost**: 梯度提升框架，用于回归任务\n- **Pandas**: 数据处理和分析\n- **NumPy**: 数值计算\n- **Scikit-learn**: 数据分割、交叉验证和评估指标\n- **Optuna**: 超参数优化框架\n- **Matplotlib/Seaborn**: 可视化图表\n- **PyYAML**: 配置文件解析\n- **Logging**: Python标准库，日志记录\n\n### 集成点\n- **数据输入**: 从CSV文件加载特征工程后的数据\n- **模型输出**: 保存训练好的XGBoost模型（.pkl格式）\n- **日志系统**: 记录训练过程、评估结果和错误信息\n- **可视化**: 生成特征重要性图并保存\n\n## Architecture\n\n### 系统架构图\n```mermaid\ngraph TD\n    A[Data Loader] --> B[Preprocessor]\n    B --> C[Model Trainer]\n    C --> D[Model Evaluator]\n    C --> E[Model Persistence]\n    D --> F[Visualizer]\n    E --> G[Trained Model]\n    G --> H[Predictor]\n    H --> I[Predictions]\n\n    subgraph \"Training Pipeline\"\n        A\n        B\n        C\n        D\n        E\n        F\n    end\n\n    subgraph \"Inference Pipeline\"\n        G\n        H\n        I\n    end\n```\n\n### 模块化设计原则\n1. **单一文件职责**: 每个Python文件只负责一个具体功能\n2. **组件隔离**: 数据加载、预处理、训练、评估、预测功能完全分离\n3. **服务层分离**: 清晰的接口定义，组件间通过函数调用通信\n4. **工具模块化**: 日志、指标计算等工具函数独立封装\n\n## Components and Interfaces\n\n### Component 1: Data Loader (data_loader.py)\n- **Purpose**: 从CSV文件加载数据，识别特征列和标签列\n- **接口**:\n  - `load_data(file_path: str) -> Tuple[pd.DataFrame, pd.Series]`: 加载数据并返回特征和标签\n  - `get_feature_names() -> List[str]`: 返回特征列名称列表\n  - `get_target_name() -> str`: 返回标签列名称\n- **依赖**: pandas, numpy\n- **重用**: Python标准文件操作和pandas的CSV读取功能\n\n### Component 2: Preprocessor (preprocessor.py)\n- **Purpose**: 数据清洗、剔除指定列、处理缺失值\n- **接口**:\n  - `__init__(columns_to_drop: List[str])`: 初始化要剔除的列\n  - `fit_transform(X: pd.DataFrame) -> pd.DataFrame`: 训练并转换数据\n  - `transform(X: pd.DataFrame) -> pd.DataFrame`: 转换新数据\n  - `get_remaining_features() -> List[str]`: 返回保留的特征列表\n- **依赖**: pandas, numpy\n- **重用**: scikit-learn的Transformer接口模式\n\n### Component 3: Model Trainer (model_trainer.py)\n- **Purpose**: XGBoost模型训练、交叉验证和超参数优化\n- **接口**:\n  - `__init__(params: Dict, use_optuna: bool = False)`: 初始化训练器\n  - `train(X_train: pd.DataFrame, y_train: pd.Series) -> xgboost.XGBRegressor`: 训练模型\n  - `cross_validate(X: pd.DataFrame, y: pd.Series, cv: int = 5) -> Dict`: 执行交叉验证\n  - `optimize_hyperparameters(X: pd.DataFrame, y: pd.Series, n_trials: int = 100)`: 超参数优化\n- **依赖**: xgboost, sklearn, optuna\n- **重用**: XGBoost的Scikit-learn兼容API\n\n### Component 4: Model Evaluator (evaluator.py)\n- **Purpose**: 评估模型性能，计算各种指标\n- **接口**:\n  - `evaluate(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]`: 评估预测结果\n  - `calculate_rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float`: 计算RMSE\n  - `calculate_mae(y_true: np.ndarray, y_pred: np.ndarray) -> float`: 计算MAE\n  - `calculate_r2(y_true: np.ndarray, y_pred: np.ndarray) -> float`: 计算R²\n  - `calculate_mape(y_true: np.ndarray, y_pred: np.ndarray) -> float`: 计算MAPE\n- **依赖**: sklearn.metrics, numpy\n- **重用**: scikit-learn的标准评估指标\n\n### Component 5: Predictor (predictor.py)\n- **Purpose**: 使用训练好的模型进行预测\n- **接口**:\n  - `__init__(model_path: str)`: 加载保存的模型\n  - `predict_single(features: Dict) -> float`: 单条记录预测\n  - `predict_batch(features_df: pd.DataFrame) -> np.ndarray`: 批量预测\n  - `predict_and_export(features_df: pd.DataFrame, output_path: str) -> None`: 预测并导出结果\n- **依赖**: xgboost, pandas, numpy\n- **重用**: joblib/pickle的模型加载机制\n\n### Component 6: Visualizer (visualizer.py)\n- **Purpose**: 生成特征重要性图和其他可视化\n- **接口**:\n  - `plot_feature_importance(model: xgboost.XGBRegressor, feature_names: List[str], output_path: str)`: 特征重要性图\n- **依赖**: matplotlib, seaborn, xgboost\n- **重用**: matplotlib的标准绘图API\n\n### Component 7: Model Persistence (model_utils.py)\n- **Purpose**: 模型和预处理器的保存与加载\n- **接口**:\n  - `save_model(model, preprocessor, feature_names: List[str], output_dir: str)`: 保存模型和元数据\n  - `load_model(model_path: str) -> Tuple[xgboost.XGBRegressor, object, List[str]]`: 加载模型和元数据\n- **依赖**: joblib, os, json\n- **重用**: joblib的序列化机制\n\n## Data Models\n\n### Model Configuration (config.yaml)\n```yaml\n# 数据配置\ndata:\n  file_path: \"data/feature_parameters.csv\"\n  target_column: \"K\"\n  columns_to_drop: [\"b\", \"h\", \"r0\", \"t\", \"L\", \"lambda\"]\n  test_size: 0.2\n  random_state: 42\n\n# XGBoost参数\nmodel:\n  params:\n    objective: \"reg:squarederror\"\n    max_depth: 6\n    learning_rate: 0.1\n    n_estimators: 200\n    subsample: 0.8\n    colsample_bytree: 0.8\n    random_state: 42\n  use_optuna: false\n  n_trials: 100\n\n# 交叉验证\ncv:\n  n_splits: 5\n  random_state: 42\n\n# 路径配置\npaths:\n  model_output: \"models/xgboost_model.pkl\"\n  preprocessor_output: \"models/preprocessor.pkl\"\n  feature_importance_plot: \"output/feature_importance.png\"\n  evaluation_report: \"output/evaluation_report.json\"\n```\n\n### Training Metadata (training_metadata.json)\n```json\n{\n  \"train_date\": \"2026-01-13T16:00:00\",\n  \"model_type\": \"XGBRegressor\",\n  \"feature_names\": [\"R\", \"fy\", \"fc\", \"e1\", \"e2\", \"r0/h\", \"b/t\", \"Ac\", \"As\", \"Re\", \"te\", \"ke\", \"xi\", \"sigma_re\", \"lambda_bar\", \"e/h\", \"e1/e2\", \"e_bar\"],\n  \"target_column\": \"K\",\n  \"train_samples\": 400,\n  \"test_samples\": 100,\n  \"cv_scores\": {\n    \"mean_rmse\": 150.5,\n    \"std_rmse\": 12.3\n  },\n  \"final_metrics\": {\n    \"rmse\": 145.2,\n    \"mae\": 118.7,\n    \"r2\": 0.9234,\n    \"mape\": 0.085\n  },\n  \"model_params\": {\n    \"objective\": \"reg:squarederror\",\n    \"max_depth\": 6,\n    \"learning_rate\": 0.1\n  }\n}\n```\n\n## Error Handling\n\n### Error Scenarios\n\n1. **文件不存在或格式错误**\n   - **处理**: 捕获FileNotFoundError和ParserError，返回清晰错误信息\n   - **用户影响**: 显示\"数据文件不存在或格式错误，请检查文件路径\"，程序退出\n\n2. **列名不匹配**\n   - **处理**: 验证所需的b, h, r₀, t, L, λ, K列是否存在\n   - **用户影响**: 显示\"缺少必要的列: [列名列表]\"，程序退出\n\n3. **数据预处理错误**\n   - **处理**: 捕获数据转换异常，检查缺失值和异常值\n   - **用户影响**: 显示\"数据预处理失败，请检查数据质量\"，输出详细错误日志\n\n4. **模型训练失败**\n   - **处理**: 捕获XGBoost训练异常，检查参数有效性\n   - **用户影响**: 显示\"模型训练失败: [错误信息]\"，保存错误日志\n\n5. **模型评估指标异常**\n   - **处理**: 检查预测值和真实值的维度匹配\n   - **用户影响**: 显示\"评估失败: 预测结果格式错误\"，要求重新运行评估\n\n6. **模型文件损坏或不存在**\n   - **处理**: 在加载模型时捕获PickleError和FileNotFoundError\n   - **用户影响**: 显示\"模型文件无效或不存在，请先训练模型\"，指导用户运行训练脚本\n\n7. **预测输入格式错误**\n   - **处理**: 验证输入特征的数量和类型，与训练时保持一致\n   - **用户影响**: 显示\"预测输入格式错误: 期望18个特征，得到[N]个\"，提供输入格式说明\n\n## Testing Strategy\n\n### Unit Testing\n- **数据加载测试**: 测试CSV读取、列识别功能\n- **预处理测试**: 测试列剔除、缺失值处理逻辑\n- **训练测试**: 测试模型训练流程（使用小数据集）\n- **评估测试**: 测试各项指标计算准确性\n- **预测测试**: 测试单条和批量预测功能\n- **模型保存/加载测试**: 测试序列化和反序列化\n\n### Integration Testing\n- **端到端训练流程**: 从数据加载到模型保存的完整流程\n- **预测流程**: 加载模型→预处理→预测→结果导出\n- **异常处理流程**: 模拟各种错误场景，验证错误处理\n\n### End-to-End Testing\n- **典型工程案例**: 使用真实的CFST柱数据训练模型\n- **跨截面预测**: 验证模型在不同截面形状上的泛化能力\n- **性能基准测试**: 评估训练时间和预测速度是否符合要求\n",
  "fileStats": {
    "size": 10972,
    "lines": 293,
    "lastModified": "2026-01-13T16:10:21.504Z"
  },
  "comments": []
}