# XGBoost 模型优化路线图

> **目标**: 将测试集 COV 降低至 0.1 以下
> **当前状态**: 测试集 COV = 0.1343
> **创建时间**: 2026-01-14

---

## 当前状态分析

### 模型评估指标

| 指标 | 训练集 | 测试集 | 目标 | 状态 |
|------|--------|--------|------|------|
| **COV (原始空间)** | 0.0800 | 0.1343 | < 0.05-0.10 | ❌ 未达标 |
| **COV (变换空间)** | 0.0109 | 0.0197 | - | ✅ 优秀 |
| **R²** | 0.9934 | 0.9776 | > 0.95 | ✅ 良好 |
| **RMSE ratio** | - | 1.89 | < 1.3 | ❌ 过拟合 |

### 关键发现

1. **对数变换有效**: 变换空间 COV 已经很低（训练 0.011，测试 0.020）
2. **过拟合明显**: RMSE ratio = 1.89，测试集误差接近训练集 2 倍
3. **误差分布不均**: 10% 的样本贡献了超过 50% 的误差
4. **离群点已部分剔除**: 已剔除 7 个极端离群点（0.17%）

---

## 分阶段优化策略

```
┌─────────────────────────────────────────────────────────────────┐
│  Stage 1 → Stage 2 → Stage 3                                    │
│  轻度调优   →  评估效果   →  决策下一步                            │
└─────────────────────────────────────────────────────────────────┘
```

---

## Stage 1: 轻度参数调优

### 目标
- 在不损失数据的情况下，尽可能降低过拟合
- 预期 COV 降至 0.10-0.12

### Optuna 搜索空间

| 参数 | 原始范围 | Stage 1 范围 | 调整方向 |
|------|----------|--------------|----------|
| max_depth | 4~9 | **3~6** | ⬇️ 轻度降低 |
| min_child_weight | 2~15 | **5~20** | ⬆️ 轻度增加 |
| subsample | 0.7~0.95 | **0.6~0.9** | ⬇️ 增加随机性 |
| colsample_bytree | 0.7~0.95 | **0.6~0.9** | ⬇️ 特征采样 |
| learning_rate | 0.01~0.15 | **0.03~0.12** | ⬇️ 降低学习率 |
| n_estimators | 300~1000 | **400~1200** | ⬆️ 补偿学习率 |
| reg_alpha | 0.05~1.5 | **0.1~2.0** | ⬆️ L1 正则 |
| reg_lambda | 0.5~5.0 | **0.5~5.0** | → 保持 |
| gamma | 0.01~0.3 | **0.01~0.3** | → 保持 |

### 配置参数
- `n_trials`: 300
- `optuna_timeout`: 7200 (2 小时)
- `use_optuna`: true

### 执行命令
```bash
cd /home/thelya/Work/xgboost
python train.py
```

---

## Stage 2: 评估 Stage 1 结果

### 决策矩阵

| Stage 1 结果 COV | 评估 | 下一步行动 |
|------------------|------|-----------|
| **< 0.10** | ✅ 优秀 | **完成！** 达到目标 |
| **0.10 ~ 0.11** | ✅ 可接受 | 微调或结束 |
| **0.11 ~ 0.12** | 🟡 需改进 | 进入 Stage 3A |
| **> 0.12** | 🟠 需加强 | 进入 Stage 3B |

### 检查点
运行以下命令查看最新评估结果：
```bash
cat output/evaluation_report.json | grep -A 5 "test_metrics_original_space"
```

---

## Stage 3: 根据结果调整

### Stage 3A: 微调（COV 0.11~0.12）

**操作选项**：
1. 剔除额外 10-20 个离群点（error > 800）
2. 或进一步微调参数范围

**离群点剔除命令**：
```bash
# 查看 error > 800 的样本数量
wc -l output/outlier_analysis.csv
# 手动确定剔除数量后，在 data/ 目录中移除对应样本
```

### Stage 3B: 中度调整（COV > 0.12）

**操作选项**：
1. 剔除额外 30-50 个离群点（error > 600）
2. 重新训练

**预期效果**：COV 降至 0.09~0.10

---

## 数据参考

### 离群点分布

| 误差阈值 | 样本数 | 占比 | 误差贡献 |
|---------|--------|------|----------|
| error >= 200 | 222 | 27.17% | 76.61% |
| error >= 500 | 82 | 10.04% | 51.32% |
| error >= 800 | 32 | 3.92% | 33.68% |
| error >= 1000 | 21 | 2.57% | 27.98% |

### 剔除离群点预估效果

| 剔除数量 | 预估 COV | 能否达标 |
|---------|----------|----------|
| 7 (已完成) | 0.1356 | ❌ |
| 20 | 0.1137 | ❌ |
| 50 | 0.0956 | ✅ |
| 100 | 0.0815 | ✅ |

---

## 风险评估

| 方案 | 成功概率 | 代价 | 建议 |
|------|----------|------|------|
| 只调优 (Stage 1) | 60-70% | 无 | **首选** |
| 调优 + 剔除 20 个 | 80% | 损失 2.4% 数据 | 次选 |
| 调优 + 剔除 50 个 | 95% | 损失 6.1% 数据 | 保底 |

---

## 执行记录

### 2026-01-14
- [x] 分析当前模型状态
- [x] 确定优化路线图
- [x] 准备 Stage 1 配置
- [ ] 执行 Stage 1 调优
- [ ] 评估 Stage 1 结果

---

## 附录

### 文件位置
- 配置文件: `config/config.yaml`
- 模型训练器: `src/model_trainer.py`
- 离群点分析: `output/outlier_analysis.csv`
- 评估报告: `output/evaluation_report.json`

### 清空调优历史
```bash
rm logs/optuna_study.db logs/best_params.json
```
