# CFST XGBoost Pipeline Configuration

# Data configuration
data:
  # Input data file path
  file_path: "data/raw/feature_parameters_unique.csv"

  # Target column name (label)
  target_column: "Nexp (kN)"

  # Target transformation configuration
  # ln(Nexp) transform to reduce impact of large values and improve COV
  target_transform:
    enabled: true
    type: "log"  # log, sqrt, none

  # Columns to drop (absolute geometric parameters)
  columns_to_drop:
    - "b (mm)"
    - "h (mm)"
    - "r0 (mm)"
    - "t (mm)"
    - "L (mm)"
    - "lambda"

  # Train-test split ratio
  test_size: 0.2

  # Random seed for reproducibility
  random_state: 42

# XGBoost model parameters
model:
  # XGBoost hyperparameters - Stage 1 Configuration
  # Designed to prevent overfitting and improve COV for outlier-heavy data
  params:
    # Learning objective
    objective: "reg:squarederror"

    # Maximum depth of trees - REDUCED to prevent overfitting to outliers
    # Target COV < 0.05 requires strong regularization
    max_depth: 4

    # Learning rate (eta) - Lowered for more stable convergence
    learning_rate: 0.08

    # Number of boosting rounds - Increased to compensate for lower depth
    n_estimators: 400

    # Subsample ratio of training instances - Increased for stability
    subsample: 0.9

    # Subsample ratio of columns for each tree - Increased for stability
    colsample_bytree: 0.9

    # Minimum child weight - INCREASED to handle outliers (380 outliers = 9.3%)
    min_child_weight: 8

    # L1 regularization - ADDED for feature selection and sparsity
    reg_alpha: 0.5

    # L2 regularization - ADDED to prevent overfitting to outliers
    reg_lambda: 2.0

    # Minimum loss reduction to make a split
    gamma: 0.1

    # Random seed
    random_state: 42

    # Tree method
    tree_method: "hist"

    # Device (use cpu to avoid GPU dependency)
    device: "cpu"

    # Number of parallel threads
    n_jobs: -1

  # Optuna hyperparameter optimization - ENABLED for Stage 2
  # Stage 1: Evaluate baseline COV with conservative parameters
  # Stage 2: Enable Optuna to target COV < 0.05
  use_optuna: false

  # Number of Optuna trials (if enabled)
  n_trials: 300

  # Optuna timeout (seconds)
  optuna_timeout: 7200  # 2 hours for thorough search

# Cross-validation configuration
cv:
  # Number of folds
  n_splits: 5

  # Random seed for split
  random_state: 42

  # Shuffle data before splitting
  shuffle: true

# Paths configuration
paths:
  # Output directory for results
  output_dir: "output"

  # Directory for saved models
  model_dir: "models"

  # Model file name
  model_output: "xgboost_model.pkl"

  # Preprocessor file name
  preprocessor_output: "preprocessor.pkl"

  # Feature names file
  feature_names_output: "feature_names.json"

  # Training metadata file
  metadata_output: "training_metadata.json"

  # Feature importance plot
  feature_importance_plot: "feature_importance.png"

  # Predictions vs actual plot
  predictions_plot: "predictions_vs_actual.png"

  # Evaluation report
  evaluation_report: "evaluation_report.json"

  # Logs directory
  logs_dir: "logs"

# Logging configuration
logging:
  # Log level (DEBUG, INFO, WARNING, ERROR)
  level: "INFO"

  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

  # Log file name
  file_name: "cfst_xgboost.log"
